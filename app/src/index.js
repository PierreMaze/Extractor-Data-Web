// app/src/index.js

import runScraper from "./features/scraper/scraper.controller.js";
import exportToExcel from "./features/excel/excel.controller.js";
import { saveProgress, loadProgress } from "./utils/saveProgress.js";
import logger from "./utils/logger.js";
import config from "./config/app.config.js";

logger.info("=== Lancement du programme ===");

// D√©termination des r√©f√©rences √† scraper en fonction de l'environnement
const { start, end } = config.refRange;
const total = end - start + 1;
logger.info(`[LOAD ‚öôÔ∏è ] R√©f√©rence ${start} ‚Üí ${end} (${total} produits)`);

// Variable globale pour cumuler les donn√©es extraites
let currentData = loadProgress(); // Si un backup existe, on le charge

// Gestion des interruptions pour sauvegarder l'√©tat en cas d'arr√™t brutal

// Pour une interruption via CTRL+C (SIGINT)
process.on("SIGINT üö´", () => {
  logger.error(
    "Interruption SIGINT d√©tect√©e, sauvegarde des donn√©es d'urgence..."
  );
  saveProgress(currentData);
  process.exit(1);
});

const main = async () => {
  try {
    // Ex√©cute le scraping
    const extratorData = await runScraper();
    // Fusionne les donn√©es existantes avec les nouvelles (pour reprendre si un backup existait)
    currentData = [...currentData, ...extratorData];
    logger.info(
      `[BACKUP ‚ÑπÔ∏è ] Nombre total de produits extraits : ${currentData.length}`
    );

    // Export en Excel
    await exportToExcel(currentData);
  } catch (error) {
    logger.error("Erreur critique dans l'application", error);
    // Sauvegarde en cas d'erreur
    saveProgress(currentData);
  } finally {
    logger.info("[SAVE üîÑÔ∏è] D√©marrage de la sauvegarde finale des donn√©es...");
    saveProgress(currentData);
    logger.info("=== Fin du programme ===");
  }
};

main();
